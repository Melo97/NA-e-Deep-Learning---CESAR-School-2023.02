{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oybr0ygpH3at"
      },
      "source": [
        "# Regressão Linear com PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AZBwvGWH3au"
      },
      "source": [
        "## Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PesKBcQYH3av"
      },
      "source": [
        "Este exemplo utiliza regressão linear para estimar o comprimento das sépalas da íris a partir do seu comprimento das pétalas.\n",
        "Utiliza-se:\n",
        "- a função de perda MSE do PyTorch,\n",
        "- treinamento dos parâmetros via gradiente descendente usando o otimizador.\n",
        "- A rede é criada com uma camada nn.Linear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPwFmfTpH3ax"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.927166Z",
          "start_time": "2017-10-08T11:23:36.900382Z"
        },
        "id": "EJa19XZsH3ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543fc7d1-6a20-48df-fb5b-568106502ee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ed265bfba90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkVqshBgH3a3"
      },
      "source": [
        "## Leitura dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.946805Z",
          "start_time": "2017-10-08T11:23:37.929142Z"
        },
        "id": "FNRdrYnrH3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c002d7b9-cb90-4734-ca47-44a1ce42ac21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (50, 1) float32\n",
            "y_train.shape: (50, 1) float32\n",
            "x_train[:5]:\n",
            " [[7. ]\n",
            " [6.4]\n",
            " [6.9]\n",
            " [5.5]\n",
            " [6.5]]\n",
            "y_train[:5]:\n",
            " [[4.7]\n",
            " [4.5]\n",
            " [4.9]\n",
            " [4. ]\n",
            " [4.6]]\n"
          ]
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "data = iris.data[iris.target==1,::2]  # comprimento das sépalas e pétalas, indices 0 e 2\n",
        "\n",
        "x_train = data[:,0:1].astype(np.float32)\n",
        "y_train = data[:,1:2].astype(np.float32)\n",
        "\n",
        "n_samples = x_train.shape[0]\n",
        "print('x_train.shape:',x_train.shape, x_train.dtype)\n",
        "print('y_train.shape:',y_train.shape, y_train.dtype)\n",
        "\n",
        "print('x_train[:5]:\\n', x_train[:5])\n",
        "print('y_train[:5]:\\n', y_train[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI2oB--zH3a7"
      },
      "source": [
        "### Normalização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.956211Z",
          "start_time": "2017-10-08T11:23:37.949927Z"
        },
        "id": "VwvLO3hIH3a9"
      },
      "outputs": [],
      "source": [
        "x_train -= x_train.min()\n",
        "x_train /= x_train.max()\n",
        "y_train -= y_train.min()\n",
        "y_train /= y_train.max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.963170Z",
          "start_time": "2017-10-08T11:23:37.958475Z"
        },
        "id": "lKjd3VQNH3a-"
      },
      "outputs": [],
      "source": [
        "x_train_bias = np.hstack([np.ones(shape=(n_samples,1)), x_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.970031Z",
          "start_time": "2017-10-08T11:23:37.965786Z"
        },
        "id": "R2gg3Z8zH3bB"
      },
      "outputs": [],
      "source": [
        "x_train_bias = torch.FloatTensor(x_train_bias)\n",
        "y_train      = torch.FloatTensor(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj_4-yzuH3bE"
      },
      "source": [
        "## Criação do modelo da rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.978113Z",
          "start_time": "2017-10-08T11:23:37.972879Z"
        },
        "id": "AxkP2_ojH3bE"
      },
      "outputs": [],
      "source": [
        "model = torch.nn.Linear(2, 1, bias=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4azDkxbH3bI"
      },
      "source": [
        "### Verificando a inicialização dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:37.989441Z",
          "start_time": "2017-10-08T11:23:37.980969Z"
        },
        "id": "hihjBHEFH3bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad20948d-2ac7-4ed8-e367-adce6c7a2a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e458ff4bc28e>:2: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  torch.nn.init.uniform(model.weight.data, -0.1, 0.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0896, -0.0064]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.weight.data = torch.zeros(1,2)\n",
        "torch.nn.init.uniform(model.weight.data, -0.1, 0.1)\n",
        "model.weight.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plBKu2guH3bM"
      },
      "source": [
        "### Testando o predict da rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:38.041043Z",
          "start_time": "2017-10-08T11:23:37.992008Z"
        },
        "id": "o9X_PZ8jH3bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64fd8e2-2354-46e0-819e-76acd45ce064"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0747],\n",
              "        [-0.0747],\n",
              "        [-0.0747],\n",
              "        [-0.0747],\n",
              "        [-0.0747]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model(Variable(torch.ones((5,2))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDVeAyDCH3bQ"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p4jG3kqH3bR"
      },
      "source": [
        "### Definindo função de perda e otimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:38.049936Z",
          "start_time": "2017-10-08T11:23:38.043559Z"
        },
        "id": "yzC5JAvtH3bR"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJe4KvCdH3bV"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:38.128839Z",
          "start_time": "2017-10-08T11:23:38.053061Z"
        },
        "id": "P_icCuI9H3bW",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbf5d73-29c1-45e6-ced5-3a700e1cc054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0896, -0.0064]])\n",
            "tensor([[0.6031, 0.3764]])\n",
            "Epoch[1/120], loss: 0.529541\n",
            "tensor([[0.6031, 0.3764]])\n",
            "tensor([[0.4143, 0.3016]])\n",
            "Epoch[2/120], loss: 0.062524\n",
            "tensor([[0.4143, 0.3016]])\n",
            "tensor([[0.4512, 0.3426]])\n",
            "Epoch[3/120], loss: 0.031301\n",
            "tensor([[0.4512, 0.3426]])\n",
            "tensor([[0.4310, 0.3530]])\n",
            "Epoch[4/120], loss: 0.028579\n",
            "tensor([[0.4310, 0.3530]])\n",
            "tensor([[0.4259, 0.3702]])\n",
            "Epoch[5/120], loss: 0.027780\n",
            "tensor([[0.4259, 0.3702]])\n",
            "tensor([[0.4174, 0.3847]])\n",
            "Epoch[6/120], loss: 0.027164\n",
            "tensor([[0.4174, 0.3847]])\n",
            "tensor([[0.4102, 0.3991]])\n",
            "Epoch[7/120], loss: 0.026611\n",
            "tensor([[0.4102, 0.3991]])\n",
            "tensor([[0.4031, 0.4126]])\n",
            "Epoch[8/120], loss: 0.026110\n",
            "tensor([[0.4031, 0.4126]])\n",
            "tensor([[0.3965, 0.4255]])\n",
            "Epoch[9/120], loss: 0.025655\n",
            "tensor([[0.3965, 0.4255]])\n",
            "tensor([[0.3901, 0.4378]])\n",
            "Epoch[10/120], loss: 0.025242\n",
            "tensor([[0.3901, 0.4378]])\n",
            "tensor([[0.3840, 0.4496]])\n",
            "Epoch[11/120], loss: 0.024867\n",
            "tensor([[0.3840, 0.4496]])\n",
            "tensor([[0.3782, 0.4607]])\n",
            "Epoch[12/120], loss: 0.024526\n",
            "tensor([[0.3782, 0.4607]])\n",
            "tensor([[0.3727, 0.4714]])\n",
            "Epoch[13/120], loss: 0.024217\n",
            "tensor([[0.3727, 0.4714]])\n",
            "tensor([[0.3675, 0.4815]])\n",
            "Epoch[14/120], loss: 0.023936\n",
            "tensor([[0.3675, 0.4815]])\n",
            "tensor([[0.3625, 0.4912]])\n",
            "Epoch[15/120], loss: 0.023682\n",
            "tensor([[0.3625, 0.4912]])\n",
            "tensor([[0.3577, 0.5004]])\n",
            "Epoch[16/120], loss: 0.023450\n",
            "tensor([[0.3577, 0.5004]])\n",
            "tensor([[0.3531, 0.5092]])\n",
            "Epoch[17/120], loss: 0.023240\n",
            "tensor([[0.3531, 0.5092]])\n",
            "tensor([[0.3488, 0.5175]])\n",
            "Epoch[18/120], loss: 0.023049\n",
            "tensor([[0.3488, 0.5175]])\n",
            "tensor([[0.3447, 0.5255]])\n",
            "Epoch[19/120], loss: 0.022876\n",
            "tensor([[0.3447, 0.5255]])\n",
            "tensor([[0.3408, 0.5331]])\n",
            "Epoch[20/120], loss: 0.022719\n",
            "tensor([[0.3408, 0.5331]])\n",
            "tensor([[0.3370, 0.5403]])\n",
            "Epoch[21/120], loss: 0.022576\n",
            "tensor([[0.3370, 0.5403]])\n",
            "tensor([[0.3334, 0.5472]])\n",
            "Epoch[22/120], loss: 0.022447\n",
            "tensor([[0.3334, 0.5472]])\n",
            "tensor([[0.3300, 0.5538]])\n",
            "Epoch[23/120], loss: 0.022329\n",
            "tensor([[0.3300, 0.5538]])\n",
            "tensor([[0.3268, 0.5600]])\n",
            "Epoch[24/120], loss: 0.022222\n",
            "tensor([[0.3268, 0.5600]])\n",
            "tensor([[0.3237, 0.5660]])\n",
            "Epoch[25/120], loss: 0.022125\n",
            "tensor([[0.3237, 0.5660]])\n",
            "tensor([[0.3208, 0.5717]])\n",
            "Epoch[26/120], loss: 0.022037\n",
            "tensor([[0.3208, 0.5717]])\n",
            "tensor([[0.3180, 0.5771]])\n",
            "Epoch[27/120], loss: 0.021957\n",
            "tensor([[0.3180, 0.5771]])\n",
            "tensor([[0.3153, 0.5823]])\n",
            "Epoch[28/120], loss: 0.021885\n",
            "tensor([[0.3153, 0.5823]])\n",
            "tensor([[0.3128, 0.5872]])\n",
            "Epoch[29/120], loss: 0.021819\n",
            "tensor([[0.3128, 0.5872]])\n",
            "tensor([[0.3103, 0.5919]])\n",
            "Epoch[30/120], loss: 0.021759\n",
            "tensor([[0.3103, 0.5919]])\n",
            "tensor([[0.3080, 0.5963]])\n",
            "Epoch[31/120], loss: 0.021705\n",
            "tensor([[0.3080, 0.5963]])\n",
            "tensor([[0.3058, 0.6006]])\n",
            "Epoch[32/120], loss: 0.021655\n",
            "tensor([[0.3058, 0.6006]])\n",
            "tensor([[0.3037, 0.6046]])\n",
            "Epoch[33/120], loss: 0.021611\n",
            "tensor([[0.3037, 0.6046]])\n",
            "tensor([[0.3017, 0.6085]])\n",
            "Epoch[34/120], loss: 0.021570\n",
            "tensor([[0.3017, 0.6085]])\n",
            "tensor([[0.2998, 0.6122]])\n",
            "Epoch[35/120], loss: 0.021533\n",
            "tensor([[0.2998, 0.6122]])\n",
            "tensor([[0.2980, 0.6157]])\n",
            "Epoch[36/120], loss: 0.021500\n",
            "tensor([[0.2980, 0.6157]])\n",
            "tensor([[0.2963, 0.6190]])\n",
            "Epoch[37/120], loss: 0.021469\n",
            "tensor([[0.2963, 0.6190]])\n",
            "tensor([[0.2946, 0.6222]])\n",
            "Epoch[38/120], loss: 0.021442\n",
            "tensor([[0.2946, 0.6222]])\n",
            "tensor([[0.2931, 0.6252]])\n",
            "Epoch[39/120], loss: 0.021417\n",
            "tensor([[0.2931, 0.6252]])\n",
            "tensor([[0.2916, 0.6281]])\n",
            "Epoch[40/120], loss: 0.021394\n",
            "tensor([[0.2916, 0.6281]])\n",
            "tensor([[0.2901, 0.6309]])\n",
            "Epoch[41/120], loss: 0.021373\n",
            "tensor([[0.2901, 0.6309]])\n",
            "tensor([[0.2888, 0.6335]])\n",
            "Epoch[42/120], loss: 0.021354\n",
            "tensor([[0.2888, 0.6335]])\n",
            "tensor([[0.2875, 0.6360]])\n",
            "Epoch[43/120], loss: 0.021337\n",
            "tensor([[0.2875, 0.6360]])\n",
            "tensor([[0.2863, 0.6384]])\n",
            "Epoch[44/120], loss: 0.021322\n",
            "tensor([[0.2863, 0.6384]])\n",
            "tensor([[0.2851, 0.6406]])\n",
            "Epoch[45/120], loss: 0.021308\n",
            "tensor([[0.2851, 0.6406]])\n",
            "tensor([[0.2840, 0.6428]])\n",
            "Epoch[46/120], loss: 0.021295\n",
            "tensor([[0.2840, 0.6428]])\n",
            "tensor([[0.2829, 0.6449]])\n",
            "Epoch[47/120], loss: 0.021284\n",
            "tensor([[0.2829, 0.6449]])\n",
            "tensor([[0.2819, 0.6468]])\n",
            "Epoch[48/120], loss: 0.021273\n",
            "tensor([[0.2819, 0.6468]])\n",
            "tensor([[0.2809, 0.6487]])\n",
            "Epoch[49/120], loss: 0.021263\n",
            "tensor([[0.2809, 0.6487]])\n",
            "tensor([[0.2800, 0.6505]])\n",
            "Epoch[50/120], loss: 0.021255\n",
            "tensor([[0.2800, 0.6505]])\n",
            "tensor([[0.2791, 0.6522]])\n",
            "Epoch[51/120], loss: 0.021247\n",
            "tensor([[0.2791, 0.6522]])\n",
            "tensor([[0.2783, 0.6538]])\n",
            "Epoch[52/120], loss: 0.021240\n",
            "tensor([[0.2783, 0.6538]])\n",
            "tensor([[0.2775, 0.6553]])\n",
            "Epoch[53/120], loss: 0.021233\n",
            "tensor([[0.2775, 0.6553]])\n",
            "tensor([[0.2767, 0.6568]])\n",
            "Epoch[54/120], loss: 0.021227\n",
            "tensor([[0.2767, 0.6568]])\n",
            "tensor([[0.2760, 0.6582]])\n",
            "Epoch[55/120], loss: 0.021222\n",
            "tensor([[0.2760, 0.6582]])\n",
            "tensor([[0.2753, 0.6595]])\n",
            "Epoch[56/120], loss: 0.021217\n",
            "tensor([[0.2753, 0.6595]])\n",
            "tensor([[0.2746, 0.6608]])\n",
            "Epoch[57/120], loss: 0.021213\n",
            "tensor([[0.2746, 0.6608]])\n",
            "tensor([[0.2740, 0.6620]])\n",
            "Epoch[58/120], loss: 0.021209\n",
            "tensor([[0.2740, 0.6620]])\n",
            "tensor([[0.2734, 0.6632]])\n",
            "Epoch[59/120], loss: 0.021205\n",
            "tensor([[0.2734, 0.6632]])\n",
            "tensor([[0.2728, 0.6643]])\n",
            "Epoch[60/120], loss: 0.021202\n",
            "tensor([[0.2728, 0.6643]])\n",
            "tensor([[0.2723, 0.6653]])\n",
            "Epoch[61/120], loss: 0.021199\n",
            "tensor([[0.2723, 0.6653]])\n",
            "tensor([[0.2718, 0.6663]])\n",
            "Epoch[62/120], loss: 0.021196\n",
            "tensor([[0.2718, 0.6663]])\n",
            "tensor([[0.2713, 0.6673]])\n",
            "Epoch[63/120], loss: 0.021194\n",
            "tensor([[0.2713, 0.6673]])\n",
            "tensor([[0.2708, 0.6682]])\n",
            "Epoch[64/120], loss: 0.021192\n",
            "tensor([[0.2708, 0.6682]])\n",
            "tensor([[0.2704, 0.6690]])\n",
            "Epoch[65/120], loss: 0.021189\n",
            "tensor([[0.2704, 0.6690]])\n",
            "tensor([[0.2699, 0.6698]])\n",
            "Epoch[66/120], loss: 0.021188\n",
            "tensor([[0.2699, 0.6698]])\n",
            "tensor([[0.2695, 0.6706]])\n",
            "Epoch[67/120], loss: 0.021186\n",
            "tensor([[0.2695, 0.6706]])\n",
            "tensor([[0.2692, 0.6714]])\n",
            "Epoch[68/120], loss: 0.021184\n",
            "tensor([[0.2692, 0.6714]])\n",
            "tensor([[0.2688, 0.6721]])\n",
            "Epoch[69/120], loss: 0.021183\n",
            "tensor([[0.2688, 0.6721]])\n",
            "tensor([[0.2684, 0.6728]])\n",
            "Epoch[70/120], loss: 0.021182\n",
            "tensor([[0.2684, 0.6728]])\n",
            "tensor([[0.2681, 0.6734]])\n",
            "Epoch[71/120], loss: 0.021181\n",
            "tensor([[0.2681, 0.6734]])\n",
            "tensor([[0.2678, 0.6740]])\n",
            "Epoch[72/120], loss: 0.021180\n",
            "tensor([[0.2678, 0.6740]])\n",
            "tensor([[0.2675, 0.6746]])\n",
            "Epoch[73/120], loss: 0.021179\n",
            "tensor([[0.2675, 0.6746]])\n",
            "tensor([[0.2672, 0.6752]])\n",
            "Epoch[74/120], loss: 0.021178\n",
            "tensor([[0.2672, 0.6752]])\n",
            "tensor([[0.2669, 0.6757]])\n",
            "Epoch[75/120], loss: 0.021177\n",
            "tensor([[0.2669, 0.6757]])\n",
            "tensor([[0.2667, 0.6762]])\n",
            "Epoch[76/120], loss: 0.021176\n",
            "tensor([[0.2667, 0.6762]])\n",
            "tensor([[0.2664, 0.6767]])\n",
            "Epoch[77/120], loss: 0.021176\n",
            "tensor([[0.2664, 0.6767]])\n",
            "tensor([[0.2662, 0.6772]])\n",
            "Epoch[78/120], loss: 0.021175\n",
            "tensor([[0.2662, 0.6772]])\n",
            "tensor([[0.2659, 0.6776]])\n",
            "Epoch[79/120], loss: 0.021175\n",
            "tensor([[0.2659, 0.6776]])\n",
            "tensor([[0.2657, 0.6780]])\n",
            "Epoch[80/120], loss: 0.021174\n",
            "tensor([[0.2657, 0.6780]])\n",
            "tensor([[0.2655, 0.6784]])\n",
            "Epoch[81/120], loss: 0.021174\n",
            "tensor([[0.2655, 0.6784]])\n",
            "tensor([[0.2653, 0.6788]])\n",
            "Epoch[82/120], loss: 0.021173\n",
            "tensor([[0.2653, 0.6788]])\n",
            "tensor([[0.2651, 0.6792]])\n",
            "Epoch[83/120], loss: 0.021173\n",
            "tensor([[0.2651, 0.6792]])\n",
            "tensor([[0.2649, 0.6795]])\n",
            "Epoch[84/120], loss: 0.021173\n",
            "tensor([[0.2649, 0.6795]])\n",
            "tensor([[0.2648, 0.6798]])\n",
            "Epoch[85/120], loss: 0.021172\n",
            "tensor([[0.2648, 0.6798]])\n",
            "tensor([[0.2646, 0.6801]])\n",
            "Epoch[86/120], loss: 0.021172\n",
            "tensor([[0.2646, 0.6801]])\n",
            "tensor([[0.2645, 0.6804]])\n",
            "Epoch[87/120], loss: 0.021172\n",
            "tensor([[0.2645, 0.6804]])\n",
            "tensor([[0.2643, 0.6807]])\n",
            "Epoch[88/120], loss: 0.021172\n",
            "tensor([[0.2643, 0.6807]])\n",
            "tensor([[0.2642, 0.6810]])\n",
            "Epoch[89/120], loss: 0.021171\n",
            "tensor([[0.2642, 0.6810]])\n",
            "tensor([[0.2640, 0.6813]])\n",
            "Epoch[90/120], loss: 0.021171\n",
            "tensor([[0.2640, 0.6813]])\n",
            "tensor([[0.2639, 0.6815]])\n",
            "Epoch[91/120], loss: 0.021171\n",
            "tensor([[0.2639, 0.6815]])\n",
            "tensor([[0.2638, 0.6817]])\n",
            "Epoch[92/120], loss: 0.021171\n",
            "tensor([[0.2638, 0.6817]])\n",
            "tensor([[0.2637, 0.6820]])\n",
            "Epoch[93/120], loss: 0.021171\n",
            "tensor([[0.2637, 0.6820]])\n",
            "tensor([[0.2636, 0.6822]])\n",
            "Epoch[94/120], loss: 0.021171\n",
            "tensor([[0.2636, 0.6822]])\n",
            "tensor([[0.2635, 0.6824]])\n",
            "Epoch[95/120], loss: 0.021171\n",
            "tensor([[0.2635, 0.6824]])\n",
            "tensor([[0.2634, 0.6826]])\n",
            "Epoch[96/120], loss: 0.021170\n",
            "tensor([[0.2634, 0.6826]])\n",
            "tensor([[0.2633, 0.6828]])\n",
            "Epoch[97/120], loss: 0.021170\n",
            "tensor([[0.2633, 0.6828]])\n",
            "tensor([[0.2632, 0.6829]])\n",
            "Epoch[98/120], loss: 0.021170\n",
            "tensor([[0.2632, 0.6829]])\n",
            "tensor([[0.2631, 0.6831]])\n",
            "Epoch[99/120], loss: 0.021170\n",
            "tensor([[0.2631, 0.6831]])\n",
            "tensor([[0.2630, 0.6833]])\n",
            "Epoch[100/120], loss: 0.021170\n",
            "tensor([[0.2630, 0.6833]])\n",
            "tensor([[0.2629, 0.6834]])\n",
            "Epoch[101/120], loss: 0.021170\n",
            "tensor([[0.2629, 0.6834]])\n",
            "tensor([[0.2629, 0.6835]])\n",
            "Epoch[102/120], loss: 0.021170\n",
            "tensor([[0.2629, 0.6835]])\n",
            "tensor([[0.2628, 0.6837]])\n",
            "Epoch[103/120], loss: 0.021170\n",
            "tensor([[0.2628, 0.6837]])\n",
            "tensor([[0.2627, 0.6838]])\n",
            "Epoch[104/120], loss: 0.021170\n",
            "tensor([[0.2627, 0.6838]])\n",
            "tensor([[0.2626, 0.6839]])\n",
            "Epoch[105/120], loss: 0.021170\n",
            "tensor([[0.2626, 0.6839]])\n",
            "tensor([[0.2626, 0.6841]])\n",
            "Epoch[106/120], loss: 0.021170\n",
            "tensor([[0.2626, 0.6841]])\n",
            "tensor([[0.2625, 0.6842]])\n",
            "Epoch[107/120], loss: 0.021170\n",
            "tensor([[0.2625, 0.6842]])\n",
            "tensor([[0.2625, 0.6843]])\n",
            "Epoch[108/120], loss: 0.021170\n",
            "tensor([[0.2625, 0.6843]])\n",
            "tensor([[0.2624, 0.6844]])\n",
            "Epoch[109/120], loss: 0.021170\n",
            "tensor([[0.2624, 0.6844]])\n",
            "tensor([[0.2624, 0.6845]])\n",
            "Epoch[110/120], loss: 0.021170\n",
            "tensor([[0.2624, 0.6845]])\n",
            "tensor([[0.2623, 0.6846]])\n",
            "Epoch[111/120], loss: 0.021170\n",
            "tensor([[0.2623, 0.6846]])\n",
            "tensor([[0.2623, 0.6847]])\n",
            "Epoch[112/120], loss: 0.021170\n",
            "tensor([[0.2623, 0.6847]])\n",
            "tensor([[0.2622, 0.6848]])\n",
            "Epoch[113/120], loss: 0.021170\n",
            "tensor([[0.2622, 0.6848]])\n",
            "tensor([[0.2622, 0.6848]])\n",
            "Epoch[114/120], loss: 0.021170\n",
            "tensor([[0.2622, 0.6848]])\n",
            "tensor([[0.2621, 0.6849]])\n",
            "Epoch[115/120], loss: 0.021170\n",
            "tensor([[0.2621, 0.6849]])\n",
            "tensor([[0.2621, 0.6850]])\n",
            "Epoch[116/120], loss: 0.021170\n",
            "tensor([[0.2621, 0.6850]])\n",
            "tensor([[0.2621, 0.6851]])\n",
            "Epoch[117/120], loss: 0.021170\n",
            "tensor([[0.2621, 0.6851]])\n",
            "tensor([[0.2620, 0.6851]])\n",
            "Epoch[118/120], loss: 0.021170\n",
            "tensor([[0.2620, 0.6851]])\n",
            "tensor([[0.2620, 0.6852]])\n",
            "Epoch[119/120], loss: 0.021170\n",
            "tensor([[0.2620, 0.6852]])\n",
            "tensor([[0.2620, 0.6852]])\n",
            "Epoch[120/120], loss: 0.021170\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 120\n",
        "w0_list = []\n",
        "w1_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    inputs = Variable(x_train_bias)\n",
        "    target = Variable(y_train)\n",
        "\n",
        "    # forward - predict\n",
        "    out = model(inputs)\n",
        "\n",
        "    #loss cálculo da função de\n",
        "    #loss = torch.mean((y_pred - y_train)**2)\n",
        "    loss = criterion(out, target)\n",
        "    print(model.weight.data)\n",
        "\n",
        "    # backward e otimizador\n",
        "    #model.weight.data = model.weight.data - learning_rate * model.weight.grad.data\n",
        "    #model.weight.grad.data.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(model.weight.data)\n",
        "\n",
        "    # verbose\n",
        "    # if (epoch+1) % 20 == 0:\n",
        "    print('Epoch[{}/{}], loss: {:.6f}'\n",
        "          .format(epoch+1, num_epochs, loss.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krvBJhZIH3bd"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-08T11:23:38.343311Z",
          "start_time": "2017-10-08T11:23:38.131051Z"
        },
        "id": "ImMHVPKMH3bf"
      },
      "outputs": [],
      "source": [
        "y_pred = model(Variable(x_train_bias))\n",
        "plt.plot(x_train, y_train.numpy(), 'ro', label='Original data')\n",
        "plt.plot(x_train, y_pred.data.numpy(), 'kx-', label='Fitting Line')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bStL-pkSH3bt"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nMQjjzmH3bt"
      },
      "source": [
        "- 1) Calcule o valor da função de custo (MSE) depois da rede treinada, utilizando a\n",
        "   função `criterion` utilizada no laço de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mz9K4egJLz5"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXPSaioJLz5"
      },
      "source": [
        "<details>\n",
        "<summary>Mostrar Resultado</summary>\n",
        "\n",
        "```python\n",
        "y_pred = model(Variable(x_train_bias))\n",
        "loss = criterion(y_pred, Variable(y_train))\n",
        "print(loss)\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xovYuu6-H3bu"
      },
      "source": [
        "- 2) Faça igual o exercício do notebook anterior, de plotar um gráfico scatterplot para\n",
        "   mostrar a evolução dos parâmetros durante o treinamento pelo gradiente descendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpXoJNmWCthR"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589mFNYIJLz5"
      },
      "source": [
        "<details>\n",
        "<summary>Mostrar Resultado</summary>\n",
        "\n",
        "```python\n",
        "plt.scatter(w0_list,w1_list)\n",
        "w0_old = None\n",
        "for (w0,w1) in zip(w0_list,w1_list):\n",
        "    if w0_old:\n",
        "        plt.arrow(w0_old, w1_old, w0-w0_old, w1-w1_old,\n",
        "                  head_length=0.01,head_width=0.01,shape='full',\n",
        "                  length_includes_head=True)\n",
        "    w0_old,w1_old = w0,w1\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "H23QVayeH3bu"
      },
      "source": [
        "- 3) Procure sobrepor a função de perda neste gráfico. (exercício mais difícil)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_si86jRH3bw"
      },
      "source": [
        "# Aprendizados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rrRR4zs3H3bx"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}